{"cells":[{"cell_type":"markdown","id":"5865cfa7-d79d-4a2e-b384-3635842ecca5","metadata":{"id":"5865cfa7-d79d-4a2e-b384-3635842ecca5"},"source":["#### Real-time Face recognition python project with OpenCV\n","\n","In this project, we will see real-time human face recognition. We will build this project in Python using OpenCV.\n","\n","We will study the Haar Cascade Classifier algorithms in OpenCV. Haar Cascade Classifier is a popular algorithm for object detection."]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjL13krKTUfw","executionInfo":{"status":"ok","timestamp":1699855841304,"user_tz":-330,"elapsed":13,"user":{"displayName":"First Project","userId":"09187870662922066516"}},"outputId":"0252a40d-f6b4-483f-d6b7-7ad772d0e879"},"id":"LjL13krKTUfw","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Nov 13 06:10:42 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","id":"2af874db-99f5-42c3-9e67-71cd8d28bcc1","metadata":{"id":"2af874db-99f5-42c3-9e67-71cd8d28bcc1"},"source":["### Face Recognition Python Project:\n","Face Recognition is a technology in computer vision. In Face recognition / detection we locate and visualize the human faces in any digital image.\n","\n","It is a subdomain of Object Detection, where we try to observe the instance of semantic objects. These objects are of particular class such as animals, cars, humans, etc. Face Detection technology has importance in many fields like marketing and security."]},{"cell_type":"markdown","id":"d76ac85f-4845-445c-bfcd-1409631c9b60","metadata":{"id":"d76ac85f-4845-445c-bfcd-1409631c9b60"},"source":["### Cascade Classifiers and Haar Features:\n","Cascade Classifiers and Haar Features are the methods used for Object Detection.\n","\n","\n","It is a machine learning algorithm where we train a cascade function with tons of images. These images are in two categories: positive images containing the target object and negative images not containing the target object.\n","\n","There are different types of cascade classifiers according to different target objects. In our project, we will use a classifier that considers the human face to recognize it as the target object.\n","\n","Haar Feature selection technique has a target to extract human face features. Haar features are like convolution kernels. These features are different permutations of black and white rectangles. In each feature calculation, we find the sum of pixels under white and black rectangles.\n","\n","\n","### Haar-cascade Detection in OpenCV:\n","OpenCV provides pre-trained models on Haar features and Cascade classifiers. These models are located in OpenCV installation. You can find the necessary XML files at:"]},{"cell_type":"markdown","id":"ebe186a6-5ece-42cd-9d05-b2094711382d","metadata":{"id":"ebe186a6-5ece-42cd-9d05-b2094711382d"},"source":["### Steps to implement human face recognition with Python & OpenCV:\n","First, create a python file face_detection.py and paste the below code:\n","\n","#### 1. Imports:"]},{"cell_type":"code","execution_count":7,"id":"ec8331e9-98d0-40e8-8048-70c9456988fd","metadata":{"id":"ec8331e9-98d0-40e8-8048-70c9456988fd","executionInfo":{"status":"ok","timestamp":1699856030146,"user_tz":-330,"elapsed":842,"user":{"displayName":"First Project","userId":"09187870662922066516"}}},"outputs":[],"source":["import os\n","import cv2"]},{"cell_type":"markdown","id":"248590c4-47fd-4e66-9249-b4aafecfa7bb","metadata":{"id":"248590c4-47fd-4e66-9249-b4aafecfa7bb"},"source":["#### 2. Initialize the classifier:"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RsKVVxCuTeBo","executionInfo":{"status":"ok","timestamp":1699856015302,"user_tz":-330,"elapsed":43951,"user":{"displayName":"First Project","userId":"09187870662922066516"}},"outputId":"74e8dce0-284f-4286-889a-06557e0c5fe8"},"id":"RsKVVxCuTeBo","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":8,"id":"b329322d-8dc1-46b5-95de-7284886c250c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b329322d-8dc1-46b5-95de-7284886c250c","executionInfo":{"status":"ok","timestamp":1699856035744,"user_tz":-330,"elapsed":912,"user":{"displayName":"First Project","userId":"09187870662922066516"}},"outputId":"6e678b4f-ea8b-47e6-80cc-66ff9a7eff97"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cascade file found.\n"]}],"source":["cascPath=os.path.dirname(cv2.__file__)+\"/data/haarcascade_frontalface_default.xml\"\n","if os.path.exists(cascPath):\n","    print(\"Cascade file found.\")\n","    faceCascade = cv2.CascadeClassifier(cascPath)\n","else:\n","    print(\"Cascade file not found at\", cascPath)"]},{"cell_type":"markdown","id":"be72c2d6-35b8-41ee-95f8-470ade029a90","metadata":{"id":"be72c2d6-35b8-41ee-95f8-470ade029a90"},"source":["#### 3. Apply faceCascade on webcam frames:"]},{"cell_type":"code","execution_count":9,"id":"e319d93d-e64a-4553-9884-db3ae7d2e47d","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":245},"id":"e319d93d-e64a-4553-9884-db3ae7d2e47d","executionInfo":{"status":"error","timestamp":1699856044635,"user_tz":-330,"elapsed":16,"user":{"displayName":"First Project","userId":"09187870662922066516"}},"outputId":"0f267824-e658-44d7-b628-f9c3c0a9185b"},"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-9e4393383b0f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Convert to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Detect faces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}],"source":["# Start video capture\n","video_capture = cv2.VideoCapture(0)\n","\n","while True:\n","    # Capture frame-by-frame\n","    ret, frames = video_capture.read()\n","\n","    # Convert to grayscale\n","    gray = cv2.cvtColor(frames, cv2.COLOR_BGR2GRAY)\n","\n","    # Detect faces\n","    faces = faceCascade.detectMultiScale(\n","        gray,\n","        scaleFactor=1.1,\n","        minNeighbors=5,\n","        flags=cv2.CASCADE_SCALE_IMAGE\n","    )\n","\n","    # Draw a rectangle around the faces\n","    for (x, y, w, h) in faces:\n","        cv2.rectangle(frames, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","\n","    # Display the resulting frame\n","    cv2.imshow('Video', frames)\n","\n","    # Break the loop with 'q' key\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# When everything is done, release the capture\n","video_capture.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":1,"id":"8b147a91-23a2-47d6-b15b-71f1752c9cfa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8b147a91-23a2-47d6-b15b-71f1752c9cfa","executionInfo":{"status":"ok","timestamp":1699856134003,"user_tz":-330,"elapsed":1802,"user":{"displayName":"First Project","userId":"09187870662922066516"}},"outputId":"a5291e0a-7ba1-4ef3-ab64-66268d8f1d5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cascade classifier loaded successfully\n"]}],"source":["import cv2\n","import os\n","\n","# Load the cascade\n","cascPath = r\"/content/drive/MyDrive/DL_project/Human Face Detection/haarcascade_frontalface_default.xml\"\n","faceCascade = cv2.CascadeClassifier(cascPath)\n","\n","# Check if the cascade is loaded successfully\n","if faceCascade.empty():\n","    print(\"Failed to load cascade classifier\")\n","    exit()\n","else:\n","    print(\"Cascade classifier loaded successfully\")\n","\n","# Start video capture\n","video_capture = cv2.VideoCapture(0)\n","\n","# Define the codec and create VideoWriter object\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n","\n","# Counter for saved images\n","image_counter = 0\n","\n","while True:\n","    # Capture frame-by-frame\n","    ret, frames = video_capture.read()\n","    if not ret:\n","        break\n","\n","    # Convert to grayscale\n","    gray = cv2.cvtColor(frames, cv2.COLOR_BGR2GRAY)\n","\n","    # Detect faces\n","    faces = faceCascade.detectMultiScale(\n","        gray,\n","        scaleFactor=1.1,\n","        minNeighbors=5,\n","        flags=cv2.CASCADE_SCALE_IMAGE\n","    )\n","\n","    # Draw a rectangle around the faces\n","    for (x, y, w, h) in faces:\n","        cv2.rectangle(frames, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","\n","    # Write the frame into the file 'output.avi'\n","    out.write(frames)\n","\n","    # Display the resulting frame\n","    cv2.imshow('Video', frames)\n","\n","    # Capture image if 'c' is pressed\n","    key = cv2.waitKey(1) & 0xFF\n","    if key == ord('c'):\n","        img_name = f\"captured_frame_{image_counter}.jpg\"\n","        cv2.imwrite(img_name, frames)\n","        print(f\"Image captured as {img_name}\")\n","        image_counter += 1\n","\n","    # Break the loop with 'q' key\n","    if key == ord('q'):\n","        break\n","\n","# Release everything when done\n","video_capture.release()\n","out.release()\n","cv2.destroyAllWindows()\n","\n"]},{"cell_type":"code","execution_count":2,"id":"1b9fcc9c-f6ee-405a-8a2b-0c495ec1c51c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1b9fcc9c-f6ee-405a-8a2b-0c495ec1c51c","executionInfo":{"status":"ok","timestamp":1699856165895,"user_tz":-330,"elapsed":11,"user":{"displayName":"First Project","userId":"09187870662922066516"}},"outputId":"bdebb385-4913-4fda-be6d-e45ff717fe47"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cascade classifier loaded successfully\n"]}],"source":["import cv2\n","import os\n","\n","# Load the cascade\n","cascPath = r\"/content/drive/MyDrive/DL_project/Human Face Detection/haarcascade_frontalface_default.xml\"\n","faceCascade = cv2.CascadeClassifier(cascPath)\n","\n","# Check if the cascade is loaded successfully\n","if faceCascade.empty():\n","    print(\"Failed to load cascade classifier\")\n","    exit()\n","else:\n","    print(\"Cascade classifier loaded successfully\")\n","\n","# Start video capture\n","video_capture = cv2.VideoCapture(0)\n","\n","# Counter for saved videos\n","video_counter = 0\n","\n","# Function to get a new video writer\n","def get_video_writer(counter):\n","    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","    filename = f'output_{counter}.avi'\n","    return cv2.VideoWriter(filename, fourcc, 20.0, (640, 480))\n","\n","# Initialize the first video writer\n","out = get_video_writer(video_counter)\n","\n","while True:\n","    # Capture frame-by-frame\n","    ret, frames = video_capture.read()\n","    if not ret:\n","        break\n","\n","    # Convert to grayscale\n","    gray = cv2.cvtColor(frames, cv2.COLOR_BGR2GRAY)\n","\n","    # Detect faces\n","    faces = faceCascade.detectMultiScale(\n","        gray,\n","        scaleFactor=1.1,\n","        minNeighbors=5,\n","        flags=cv2.CASCADE_SCALE_IMAGE\n","    )\n","\n","    # Draw a rectangle around the faces\n","    for (x, y, w, h) in faces:\n","        cv2.rectangle(frames, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","\n","    # Write the frame into the current video file\n","    out.write(frames)\n","\n","    # Display the resulting frame\n","    cv2.imshow('Video', frames)\n","\n","    # Check for key presses\n","    key = cv2.waitKey(1) & 0xFF\n","\n","    # Start a new video recording if 'v' is pressed\n","    if key == ord('v'):\n","        out.release()  # Release the current video writer\n","        video_counter += 1\n","        out = get_video_writer(video_counter)  # Create a new video writer\n","        print(f\"Started recording video: output_{video_counter}.avi\")\n","\n","    # Break the loop with 'q' key\n","    if key == ord('q'):\n","        break\n","\n","# Release everything when done\n","video_capture.release()\n","out.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":1,"id":"4530bc4a-63f9-481d-9610-d37e2f837ea5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4530bc4a-63f9-481d-9610-d37e2f837ea5","executionInfo":{"status":"ok","timestamp":1699856197456,"user_tz":-330,"elapsed":7,"user":{"displayName":"First Project","userId":"09187870662922066516"}},"outputId":"697cb270-44a7-471c-a452-d9138db5a7e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cascade classifier loaded successfully\n"]}],"source":["import cv2\n","import os\n","\n","# Load the cascade\n","cascPath = r\"/content/drive/MyDrive/DL_project/Human Face Detection/haarcascade_frontalface_default.xml\"\n","faceCascade = cv2.CascadeClassifier(cascPath)\n","\n","# Check if the cascade is loaded successfully\n","if faceCascade.empty():\n","    print(\"Failed to load cascade classifier\")\n","    exit()\n","else:\n","    print(\"Cascade classifier loaded successfully\")\n","\n","# Start video capture\n","video_capture = cv2.VideoCapture(0)\n","\n","# Counters for saved videos and images\n","video_counter = 0\n","image_counter = 0\n","\n","# Function to get a new video writer\n","def get_video_writer(counter):\n","    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","    filename = f'output_{counter}.avi'\n","    return cv2.VideoWriter(filename, fourcc, 20.0, (640, 480))\n","\n","# Initialize the first video writer\n","out = get_video_writer(video_counter)\n","\n","while True:\n","    # Capture frame-by-frame\n","    ret, frames = video_capture.read()\n","    if not ret:\n","        break\n","\n","    # Convert to grayscale\n","    gray = cv2.cvtColor(frames, cv2.COLOR_BGR2GRAY)\n","\n","    # Detect faces\n","    faces = faceCascade.detectMultiScale(\n","        gray,\n","        scaleFactor=1.1,\n","        minNeighbors=5,\n","        flags=cv2.CASCADE_SCALE_IMAGE\n","    )\n","\n","    # Draw a rectangle around the faces\n","    for (x, y, w, h) in faces:\n","        cv2.rectangle(frames, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","\n","    # Write the frame into the current video file\n","    out.write(frames)\n","\n","    # Display the resulting frame\n","    cv2.imshow('Video', frames)\n","\n","    # Check for key presses\n","    key = cv2.waitKey(1) & 0xFF\n","\n","    # Capture image if 'c' is pressed\n","    if key == ord('c'):\n","        img_name = f\"captured_frame_{image_counter}.jpg\"\n","        cv2.imwrite(img_name, frames)\n","        print(f\"Image captured as {img_name}\")\n","        image_counter += 1\n","\n","    # Start a new video recording if 'v' is pressed\n","    if key == ord('v'):\n","        out.release()  # Release the current video writer\n","        video_counter += 1\n","        out = get_video_writer(video_counter)  # Create a new video writer\n","        print(f\"Started recording video: output_{video_counter}.avi\")\n","\n","    # Break the loop with 'q' key\n","    if key == ord('q'):\n","        break\n","\n","# Release everything when done\n","video_capture.release()\n","out.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","source":["!pip install --upgrade gradio\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0NI0uRzuU378","executionInfo":{"status":"ok","timestamp":1699856354497,"user_tz":-330,"elapsed":4465,"user":{"displayName":"First Project","userId":"09187870662922066516"}},"outputId":"5f5ff1d2-9564-4b36-88b7-c87c62135a9f"},"id":"0NI0uRzuU378","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.2.0)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.104.1)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n","Requirement already satisfied: gradio-client==0.7.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.0)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.0)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.4.2)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n","Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.8.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.0.post1)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0->gradio) (2023.6.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.44.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.10.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.10.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n","Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n","Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n","Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.6.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n","Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n","Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n","Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"]}]},{"cell_type":"code","execution_count":6,"id":"a82716b6-261a-49f5-bddf-6b49b8221926","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"a82716b6-261a-49f5-bddf-6b49b8221926","executionInfo":{"status":"error","timestamp":1699856414193,"user_tz":-330,"elapsed":843,"user":{"displayName":"First Project","userId":"09187870662922066516"}},"outputId":"4318b2bb-d743-4113-8a85-8a3128ee5e77"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-c6eff03a6c06>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m iface = gr.Interface(\n\u001b[1;32m     35\u001b[0m     \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetect_faces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"webcam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Updated syntax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pil\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Face Detection\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gradio/component_meta.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Image.__init__() got an unexpected keyword argument 'source'"]}],"source":["import gradio as gr\n","import cv2\n","import numpy as np\n","\n","# Function to perform face detection\n","def detect_faces(image):\n","    # Convert the image to grayscale\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # Load the cascade\n","    cascPath = \"/content/drive/MyDrive/DL_project/Human Face Detection/haarcascade_frontalface_default.xml\"  # Update this path\n","    faceCascade = cv2.CascadeClassifier(cascPath)\n","\n","    # Check if cascade is loaded\n","    if faceCascade.empty():\n","        print(\"Failed to load cascade classifier\")\n","        return image  # return the original image if cascade loading fails\n","\n","    # Detect faces\n","    faces = faceCascade.detectMultiScale(\n","        gray,\n","        scaleFactor=1.1,\n","        minNeighbors=5,\n","        flags=cv2.CASCADE_SCALE_IMAGE\n","    )\n","\n","    # Draw rectangles around faces\n","    for (x, y, w, h) in faces:\n","        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","\n","    return image\n","\n","# Create a Gradio interface\n","iface = gr.Interface(\n","    fn=detect_faces,\n","    inputs=gr.Image(source=\"webcam\"),  # Updated syntax\n","    outputs=gr.Image(type=\"pil\"),\n","    title=\"Face Detection\",\n","    description=\"Upload an image or use your webcam to capture a photo. The app will detect faces and draw rectangles around them.\"\n",")\n","\n","iface.launch()\n"]},{"cell_type":"code","execution_count":10,"id":"664e227a-45e6-43bc-9e7b-32debe2415f6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":626},"id":"664e227a-45e6-43bc-9e7b-32debe2415f6","executionInfo":{"status":"ok","timestamp":1699856645132,"user_tz":-330,"elapsed":2677,"user":{"displayName":"First Project","userId":"09187870662922066516"}},"outputId":"acc9a742-ec07-4265-f5f0-38ff5c431bfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Running on public URL: https://8cbcca511ed133dc1e.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://8cbcca511ed133dc1e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":10}],"source":["import gradio as gr\n","import cv2\n","import numpy as np\n","\n","# Function to perform face detection\n","def detect_faces(image):\n","    # Convert the image to grayscale\n","    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # Load the cascade\n","    cascPath = \"/content/drive/MyDrive/DL_project/Human Face Detection/haarcascade_frontalface_default.xml\"  # Update this path\n","    faceCascade = cv2.CascadeClassifier(cascPath)\n","\n","    # Check if cascade is loaded\n","    if faceCascade.empty():\n","        print(\"Failed to load cascade classifier\")\n","        return image  # return the original image if cascade loading fails\n","\n","    # Detect faces\n","    faces = faceCascade.detectMultiScale(\n","        gray,\n","        scaleFactor=1.1,\n","        minNeighbors=5,\n","        flags=cv2.CASCADE_SCALE_IMAGE\n","    )\n","\n","    # Draw rectangles around faces\n","    for (x, y, w, h) in faces:\n","        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n","\n","    return image\n","\n","# Create a Gradio interface\n","iface = gr.Interface(\n","    fn=detect_faces,\n","    inputs=gr.Image(type=\"pil\"),  # Default input component\n","    outputs=gr.Image(type=\"pil\"),\n","    title=\"Face Detection\",\n","    description=\"Upload an image or use your webcam to capture a photo. The app will detect faces and draw rectangles around them.\"\n",")\n","\n","iface.launch()\n"]},{"cell_type":"code","source":[],"metadata":{"id":"k9S3Nu0vV-FY"},"id":"k9S3Nu0vV-FY","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}